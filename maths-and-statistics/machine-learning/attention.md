# Attention


* [Attention is all you need - paper](https://arxiv.org/abs/1706.03762)
* [Attention is all you need - VIDEO](https://www.youtube.com/watch?v=iDulhoQ2pro)

* [Transformers are Graph networks](https://graphdeeplearning.github.io/post/transformers-are-gnns/)
